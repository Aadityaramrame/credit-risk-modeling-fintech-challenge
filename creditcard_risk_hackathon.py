# -*- coding: utf-8 -*-
"""CREDITCARD_RISK_HACKATHON.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fQc7lN3t1Mz6Wuc_wxjCh5ShwQ79TW3Q

# **Import Libraries**

```
# This is formatted as code
```

# New Section
"""

# Cell 1: Import necessary libraries

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix

"""# **Load the Datasets**"""

#Load the raw datasets

application_df = pd.read_csv("/content/application_record.csv")
credit_df = pd.read_csv("/content/credit_record.csv")

application_df.head()

credit_df.head()

"""# **Quick Shape + Info Check**"""

# Cell 3: Initial overview of the datasets

print("Application DF:", application_df.shape)
print(application_df.info())

print("\nCredit DF:", credit_df.shape)
print(credit_df.info())

"""# **Checking for Total Number of Null Values in each Dataset.**"""

application_df.head().isnull().sum().sum()

credit_df.head().isnull().sum().sum()

"""# **Checking the unique IDs in both dataset**"""

print("Number of unique IDs in application_df:", application_df['ID'].nunique())
print("Number of unique IDs in credit_df:", credit_df['ID'].nunique())

unique_ids_application = set(application_df['ID'].unique())
unique_ids_credit = set(credit_df['ID'].unique())

common_ids = unique_ids_application.intersection(unique_ids_credit)

print(f"Number of IDs in credit_df that also exist in application_df: {len(common_ids)}")

"""# **PREPROCESS THE application_df**"""

print(application_df['CODE_GENDER'].value_counts())

print(application_df['FLAG_OWN_CAR'].value_counts())

print(application_df['FLAG_OWN_REALTY'].value_counts())

print(application_df['CNT_CHILDREN'].value_counts())

# Create a mapping dictionary for all text-based child counts
mapping = {
    'Not yet': 0, 'No': 0, 'zero': 0, 'Zero': 0,
    'one': 1, 'One': 1, 'Single': 1,
    'two': 2, 'Two': 2, 'Pair': 2, 'Twins': 2,
    'three': 3, 'Three': 3, 'Triplets': 3,
    'four': 4, 'Four': 4,
    'Five': 5, 'five': 5,
    'six': 6, 'Six': 6,
    'seven': 7, 'Seven': 7,
    'nine': 9, 'Nine': 9,
    'twelve': 12, 'Twelve': 12,
    'fourteen': 14, 'Fourteen': 14,
    'nineteen': 19, 'Nineteen': 19
}

# Replace using mapping
application_df['CNT_CHILDREN'] = application_df['CNT_CHILDREN'].replace(mapping)

# Convert numeric strings → int
application_df['CNT_CHILDREN'] = pd.to_numeric(application_df['CNT_CHILDREN'], errors='coerce')

# OPTIONAL: Fill remaining NaN (if any)
application_df['CNT_CHILDREN'] = application_df['CNT_CHILDREN'].fillna(0).astype(int)

print(application_df['CNT_CHILDREN'].value_counts())

print(application_df['AMT_INCOME_TOTAL'].value_counts())

# Function to convert income strings (e.g., '1.35M', '135k') to numeric
def convert_income_to_numeric(income_str):
    if isinstance(income_str, (int, float)):
        return income_str # Already numeric
    income_str = str(income_str).strip().lower()
    if 'm' in income_str:
        return float(income_str.replace('m', '')) * 1_000_000
    elif 'k' in income_str:
        return float(income_str.replace('k', '')) * 1_000
    else:
        return float(income_str)

# Apply the conversion function to the 'AMT_INCOME_TOTAL' column
application_df['AMT_INCOME_TOTAL'] = application_df['AMT_INCOME_TOTAL'].apply(convert_income_to_numeric)

print(application_df['AMT_INCOME_TOTAL'].value_counts())

print(application_df['NAME_INCOME_TYPE'].value_counts())

print(application_df['NAME_EDUCATION_TYPE'].value_counts())

print(application_df['NAME_FAMILY_STATUS'].value_counts())

print(application_df['NAME_HOUSING_TYPE'].value_counts())

def combine_housing_type(x):
    if x in ['House / apartment', 'Private House', 'Private Flat']:
        return 'Private/Home'
    elif x in ['With parents', 'Parents Place', 'Parents Home']:
        return 'With Parents'
    elif x in ['Rented apartment', 'Rental Home', 'Rental Unit']:
        return 'Rented'
    elif x in ['Office apartment', 'Corporate Flat', 'Corporate House']:
        return 'Corporate'
    elif x in ['Municipal apartment', 'Govt Housing', 'Govt Flat', 'Co-op apartment']:
        return 'Govt/Co-op'
    elif x in ['Society Housing', 'Society Flat']:
        return 'Society'
    else:
        return x

application_df['NAME_HOUSING_TYPE'] = application_df['NAME_HOUSING_TYPE'].apply(combine_housing_type)

print(application_df['NAME_HOUSING_TYPE'].value_counts())

import pandas as pd
import re
import numpy as np

def convert_age_to_years(x):
    if pd.isnull(x):
        return np.nan

    x = str(x).lower().replace(" ", "")

    # Match patterns like 32y0m27d or 36y11m12d
    match = re.match(r'(\d+)[yY](\d+)[mM](\d+)[dD]', x)
    if match:
        years = int(match.group(1))
        months = int(match.group(2))
        days = int(match.group(3))
        return years + months/12 + days/365

    # Match patterns like 26yrs3mon23days
    match = re.match(r'(\d+)yrs?(\d+)mon(\d+)days?', x)
    if match:
        years = int(match.group(1))
        months = int(match.group(2))
        days = int(match.group(3))
        return years + months/12 + days/365

    # Match just years if present
    match = re.match(r'(\d+)[yY]', x)
    if match:
        return int(match.group(1))

    # If nothing matches, return NaN
    return np.nan

# Apply conversion
application_df['AGE_YEARS'] = application_df['DAYS_BIRTH'].apply(convert_age_to_years)

# Fill missing values with median
median_age = application_df['AGE_YEARS'].median()
application_df['AGE_YEARS'] = application_df['AGE_YEARS'].fillna(median_age)

# Check
print(application_df['AGE_YEARS'].describe())

print(application_df['DAYS_BIRTH'].value_counts())

import matplotlib.pyplot as plt

application_df['AGE_YEARS'].hist(bins=50, figsize=(10,5))
plt.title("Age Distribution of Applicants")
plt.xlabel("Age (Years)")
plt.ylabel("Count")
plt.show()

print(application_df['DAYS_EMPLOYED'].value_counts())

print(application_df['FLAG_MOBIL'].value_counts())

application_df = application_df.drop('FLAG_MOBIL', axis=1)
print("'FLAG_MOBIL' column dropped successfully.")

print(application_df['FLAG_WORK_PHONE'].value_counts())

# Convert all entries to lowercase strings
application_df['FLAG_WORK_PHONE_CLEAN'] = application_df['FLAG_WORK_PHONE'].astype(str).str.lower()

# Map all “yes/true/verified/provided/y” values to 1
yes_values = ['1', 'y', 'yes', 'true', 'verified', 'provided']
application_df['FLAG_WORK_PHONE_CLEAN'] = application_df['FLAG_WORK_PHONE_CLEAN'].replace(yes_values, 1)

# Map all “no/false/n/not shared/missing/0” values to 0
no_values = ['0', 'n', 'no', 'false', 'not shared', 'missing']
application_df['FLAG_WORK_PHONE_CLEAN'] = application_df['FLAG_WORK_PHONE_CLEAN'].replace(no_values, 0)

# Convert to integer type
application_df['FLAG_WORK_PHONE_CLEAN'] = application_df['FLAG_WORK_PHONE_CLEAN'].astype(int)

# Check result
print(application_df['FLAG_WORK_PHONE_CLEAN'].value_counts())

# Check result
print(application_df['FLAG_PHONE'].value_counts())

# Convert all entries to lowercase strings
application_df['FLAG_PHONE_CLEAN'] = application_df['FLAG_PHONE'].astype(str).str.lower()

# Map all “yes/true/verified/provided/y/1” values to 1
yes_values = ['1', 'y', 'yes', 'true', 'verified', 'provided']
application_df['FLAG_PHONE_CLEAN'] = application_df['FLAG_PHONE_CLEAN'].replace(yes_values, 1)

# Map all “no/false/n/not shared/missing/0” values to 0
no_values = ['0', 'n', 'no', 'false', 'not shared', 'missing']
application_df['FLAG_PHONE_CLEAN'] = application_df['FLAG_PHONE_CLEAN'].replace(no_values, 0)

# Convert to integer type
application_df['FLAG_PHONE_CLEAN'] = application_df['FLAG_PHONE_CLEAN'].astype(int)

# Check result
print(application_df['FLAG_PHONE_CLEAN'].value_counts())

# Check result
print(application_df['FLAG_EMAIL'].value_counts())

# Convert all entries to lowercase strings
application_df['FLAG_EMAIL_CLEAN'] = application_df['FLAG_EMAIL'].astype(str).str.lower()

# Map all “yes/true/verified/provided/y/1” values to 1
yes_values = ['1', 'y', 'yes', 'true', 'verified', 'provided']
application_df['FLAG_EMAIL_CLEAN'] = application_df['FLAG_EMAIL_CLEAN'].replace(yes_values, 1)

# Map all “no/false/n/not shared/missing/0” values to 0
no_values = ['0', 'n', 'no', 'false', 'not shared', 'missing']
application_df['FLAG_EMAIL_CLEAN'] = application_df['FLAG_EMAIL_CLEAN'].replace(no_values, 0)

# Convert to integer type
application_df['FLAG_EMAIL_CLEAN'] = application_df['FLAG_EMAIL_CLEAN'].astype(int)

# Check result
print(application_df['FLAG_EMAIL_CLEAN'].value_counts())

# Check result
print(application_df['OCCUPATION_TYPE'].value_counts())

# Check result
print(application_df['CNT_FAM_MEMBERS'].value_counts())

application_df['CNT_FAM_MEMBERS'] = application_df['CNT_FAM_MEMBERS'].astype(int)
print(application_df['CNT_FAM_MEMBERS'].value_counts())

application_df.head()

print(application_df.columns)

cols_to_drop = ['FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL']

application_df = application_df.drop(columns=cols_to_drop)

# check final columns
application_df.columns

application_df.columns.isnull().sum().sum()

"""# **PREPROCESSING IS DONE FOR application_df!!**

1.   List item
2.   List item

**PREPROCESSING THE credit_record.csv file**
"""

credit_df.head()

# Check result
print(credit_df['ID'].value_counts())

# Check result
print(credit_df['MONTHS_BALANCE'].value_counts())

# ===============================
# 2. CHECK UNIQUE VALUES & DISTRIBUTIONS
# ===============================

print("\nUnique STATUS values:")
print(credit_df['STATUS'].unique())

print("\nDistribution of STATUS:")
print(credit_df['STATUS'].value_counts())

print("\nDistribution of MONTHS_BALANCE:")
print(credit_df['MONTHS_BALANCE'].describe())
print(credit_df['MONTHS_BALANCE'].value_counts().head(20))

# ===============================
# 3. CLEAN STATUS COLUMN
# ===============================
# Bank default rule: STATUS >= '2' means >=60 days overdue → BAD

def map_status_to_bad(x):
    # Severe overdue
    if x in ['2', '3', '4', '5']:
        return 1
    # Good / No credit / small delay
    else:
        return 0

credit_df['BAD_FLAG'] = credit_df['STATUS'].apply(map_status_to_bad)

print("\nBAD_FLAG distribution:")
print(credit_df['BAD_FLAG'].value_counts())

# Keep only ID + BAD_FLAG
credit_targets = credit_df[['ID', 'BAD_FLAG']]

# Merge only the IDs that exist in both datasets
train_df = application_df.merge(credit_targets, on='ID', how='inner')

print(train_df.shape)
print(train_df['BAD_FLAG'].value_counts())

# Define target and features
y = train_df['BAD_FLAG']
X = train_df.drop(columns=['BAD_FLAG'])

print("Class distribution before SMOTE:")
print(y.value_counts())

print("\nPercentage distribution:")
print((y.value_counts(normalize=True) * 100).round(4))

import plotly.express as px
import pandas as pd

# Calculate value counts and percentages
class_distribution = y.value_counts().reset_index()
class_distribution.columns = ['BAD_FLAG', 'Count']
class_distribution['Percentage'] = (class_distribution['Count'] / class_distribution['Count'].sum()) * 100

# Create a Plotly bar chart
fig = px.bar(
    class_distribution,
    x='BAD_FLAG',
    y='Count',
    color='BAD_FLAG',
    text=class_distribution.apply(lambda row: f"{row['Count']}<br>{row['Percentage']:.2f}%", axis=1),
    title='Class Distribution of BAD_FLAG (Before SMOTE)',
    labels={'BAD_FLAG': 'Credit Risk Status', 'Count': 'Number of Applicants'}
)

fig.update_layout(
    xaxis = dict(
        tickmode = 'array',
        tickvals = [0, 1],
        ticktext = ['Good (0)', 'Bad (1)']
    )
)

fig.show()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Training shape:", X_train.shape, y_train.shape)
print("Testing shape:", X_test.shape, y_test.shape)

df = train_df.copy()

cols_to_drop = ['DAYS_BIRTH', 'DAYS_EMPLOYED']
df = df.drop(columns=cols_to_drop)

from sklearn.preprocessing import LabelEncoder

categorical_cols = [
    'CODE_GENDER',
    'FLAG_OWN_CAR',
    'FLAG_OWN_REALTY',
    'NAME_INCOME_TYPE',
    'NAME_EDUCATION_TYPE',
    'NAME_FAMILY_STATUS',
    'NAME_HOUSING_TYPE',
    'OCCUPATION_TYPE'
]

label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))
    label_encoders[col] = le

print("Encoding complete.")

y = df['BAD_FLAG']
X = df.drop(columns=['BAD_FLAG'])

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

smote = SMOTE(random_state=42)
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)

print("Before SMOTE:")
print(y_train.value_counts())
print("\nPercentage:")
print((y_train.value_counts(normalize=True) * 100).round(4))

print("\nAfter SMOTE:")
print(y_train_sm.value_counts())
print("\nPercentage:")
print((y_train_sm.value_counts(normalize=True) * 100).round(4))

import matplotlib.pyplot as plt
import seaborn as sns

fig, ax = plt.subplots(1, 2, figsize=(12, 5))

sns.countplot(x=y_train, ax=ax[0])
ax[0].set_title("Before SMOTE")
ax[0].set_xlabel("BAD_FLAG")

sns.countplot(x=y_train_sm, ax=ax[1])
ax[1].set_title("After SMOTE")
ax[1].set_xlabel("BAD_FLAG")

plt.show()

from sklearn.model_selection import train_test_split

# Split train_smote into train + validation
X_train_final, X_val, y_train_final, y_val = train_test_split(
    X_train_sm, y_train_sm, test_size=0.2, random_state=42, stratify=y_train_sm
)

print("Training shape:", X_train_final.shape)
print("Validation shape:", X_val.shape)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, recall_score, confusion_matrix

# Initialize Random Forest
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    random_state=42,
    n_jobs=-1,
    class_weight='balanced'  # helps with imbalanced dataset
)

# 5-fold Cross Validation on training set
cv_accuracy = cross_val_score(rf, X_train_final, y_train_final, cv=5, scoring='accuracy')
cv_recall = cross_val_score(rf, X_train_final, y_train_final, cv=5, scoring='recall')

print("Cross-validated Accuracy:", cv_accuracy.mean().round(4))
print("Cross-validated Recall:", cv_recall.mean().round(4))

# Fit RF on training data
rf.fit(X_train_final, y_train_final)

# Predict on Validation Set
y_val_pred = rf.predict(X_val)

# Evaluate
val_accuracy = accuracy_score(y_val, y_val_pred)
val_recall = recall_score(y_val, y_val_pred)
cm = confusion_matrix(y_val, y_val_pred)
print("\nValidation Accuracy:", round(val_accuracy, 4))
print("Validation Recall:", round(val_recall, 4))
print("\nConfusion Matrix:\n", cm)

import matplotlib.pyplot as plt
import pandas as pd

feat_importances = pd.Series(rf.feature_importances_, index=X_train_final.columns)
feat_importances.sort_values(ascending=False).plot(kind='bar', figsize=(12,5))
plt.title("Feature Importances - Random Forest")
plt.show()

# Predict on real test set
y_test_pred = rf.predict(X_test)

from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report

test_accuracy = accuracy_score(y_test, y_test_pred)
test_recall = recall_score(y_test, y_test_pred)
cm_test = confusion_matrix(y_test, y_test_pred)

print("Test Accuracy:", round(test_accuracy,4))
print("Test Recall:", round(test_recall,4))
print("\nConfusion Matrix (Test Set):\n", cm_test)

# Optional: detailed classification report
print("\nClassification Report (Test Set):")
print(classification_report(y_test, y_test_pred))

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report

# Initialize XGBoost classifier
xgb_clf = XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42,
    scale_pos_weight = (len(y_train_final) - sum(y_train_final)) / sum(y_train_final)  # handle imbalance
)

# Train
xgb_clf.fit(X_train_final, y_train_final)

# Validation prediction
y_val_pred = xgb_clf.predict(X_val)
val_accuracy = accuracy_score(y_val, y_val_pred)
val_recall = recall_score(y_val, y_val_pred)
cm = confusion_matrix(y_val, y_val_pred)

print("Validation Accuracy:", round(val_accuracy,4))
print("Validation Recall:", round(val_recall,4))
print("\nConfusion Matrix:\n", cm)

# Predict on real test set
y_test_pred = xgb_clf.predict(X_test)

from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report

test_accuracy = accuracy_score(y_test, y_test_pred)
test_recall = recall_score(y_test, y_test_pred)
cm_test = confusion_matrix(y_test, y_test_pred)

print("XGBoost Test Accuracy:", round(test_accuracy,4))
print("XGBoost Test Recall:", round(test_recall,4))
print("\nConfusion Matrix (Test Set):\n", cm_test)
print("\nClassification Report (Test Set):")
print(classification_report(y_test, y_test_pred))

import lightgbm as lgb
from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report

# Initialize LightGBM classifier
lgb_clf = lgb.LGBMClassifier(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=7,
    num_leaves=31,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    class_weight='balanced'  # handles class imbalance
)

# Train on SMOTE-balanced training data
lgb_clf.fit(X_train_final, y_train_final)

# Validate on validation set
y_val_pred = lgb_clf.predict(X_val)
val_accuracy = accuracy_score(y_val, y_val_pred)
val_recall = recall_score(y_val, y_val_pred)
cm_val = confusion_matrix(y_val, y_val_pred)

print("Validation Accuracy:", round(val_accuracy,4))
print("Validation Recall:", round(val_recall,4))
print("\nConfusion Matrix (Validation Set):\n", cm_val)

# Test on real test set
y_test_pred = lgb_clf.predict(X_test)
test_accuracy = accuracy_score(y_test, y_test_pred)
test_recall = recall_score(y_test, y_test_pred)
cm_test = confusion_matrix(y_test, y_test_pred)

print("\nLightGBM Test Accuracy:", round(test_accuracy,4))
print("LightGBM Test Recall:", round(test_recall,4))
print("\nConfusion Matrix (Test Set):\n", cm_test)
print("\nClassification Report (Test Set):")
print(classification_report(y_test, y_test_pred))

